#!/usr/bin/env -S poetry run python
import io
import itertools
import os
import re
import subprocess
from io import StringIO
from subprocess import Popen
from typing import Optional, Dict, List

import defopt
import mlflow
from fabric import Connection
from mlflow.tracking import MlflowClient


CLUSTERS = {
    'cedar': ('cedar.computecanada.ca', 'def-ibajic'),
    'cedar-priority': ('cedar.computecanada.ca', 'rrg-ibajic'),
    'graham': ('graham.computecanada.ca', 'def-ibajic'),
    'narval': ('narval.computecanada.ca', 'def-ibajic'),
}


class KeywordArguments(dict, Dict[str, str]):
    @classmethod
    def from_string(cls, string: str) -> 'KeywordArguments':
        return KeywordArguments({
            key.strip().replace('_', '-'): value
            for key, value in (
                kwarg.split('=')
                for kwarg in re.findall(r',?(.*?=.*?)(?=,[^,]*=|$)', string)
            )
        })


class ArgumentsSets(dict, Dict[str, List[str]]):
    @classmethod
    def from_string(cls, string) -> 'ArgumentsSets':
        return ArgumentsSets({
            key: [value.strip() for value in value.split(',')]
            for key, value
            in KeywordArguments.from_string(string).items()
        })


def get_argument_combinations(arguments_sets: Dict[str, List[str]]) -> List[Dict[str, str]]:
    return [
        dict(zip(arguments_sets.keys(), combination))
        for combination in itertools.product(*arguments_sets.values())
    ]


def create_process(*args: str) -> Popen:
    return Popen(
        args,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        close_fds=True,
        universal_newlines=True,
    )


def run_command(*args: str, stdin: Optional[str] = None) -> str:
    process = create_process(*args)

    stdout, stderr = process.communicate(input=stdin)

    if process.returncode != 0:
        raise OSError(stderr)

    response = stdout.strip()

    return response


def create_run_id(
        experiment_name: str,
        user: str,
        entry_point: str,
        repository_url: str,
        version: str,
        branch: str,
        path: str,
        image: str,
        run_name: Optional[str] = None,
        note: Optional[str] = None,
) -> str:

    client = MlflowClient()

    experiment = client.get_experiment_by_name(experiment_name)

    if experiment is None:
        raise ValueError(f'Experiment {experiment_name} does not exist.')

    tags = {
        'mlflow.user': user,
        'mlflow.project.env': 'docker',
        'mlflow.project.entryPoint': entry_point,
        'mlflow.source.type': 'PROJECT',
        'mlflow.source.name': f'https://{repository_url.removesuffix(".git")}#{path}',
        'mlflow.source.git.commit': version,
        'mlflow.source.git.branch': branch,
        'mlflow.source.git.repoURL': repository_url,
        'mlflow.docker.image.name': image,
    }

    if note is not None:
        tags['mlflow.note.content'] = note

    run = client.create_run(experiment.experiment_id, tags=tags, run_name=run_name)

    run_id = run.info.run_id

    return run_id


def get_arguments(run_id: str) -> KeywordArguments:
    return KeywordArguments({
        key: str(value)
        for key, value
        in mlflow.get_run(run_id).data.params.items()
        if value != 'None'
    })


def get_experiment_name(run_id: str) -> str:
    return mlflow.get_experiment(mlflow.get_run(run_id).info.experiment_id).name


def get_entry_point(run_id: str) -> str:
    return mlflow.get_run(run_id).data.tags['mlflow.project.entryPoint']


def get_version(run_id: str) -> str:
    return mlflow.get_run(run_id).data.tags['mlflow.source.git.commit']


def get_repository_url() -> str:
    repository_url = run_command('git', 'config', '--get', 'remote.origin.url')

    if repository_url.startswith('https://'):
        repository_url = repository_url.removeprefix('https://')
    else:
        repository_url = repository_url.removeprefix('git@').replace(':', '/')

    return repository_url


def main(
        *,
        experiment_name: Optional[str] = None,
        entry_point: Optional[str] = None,
        version: Optional[str] = None,
        run_id: Optional[str] = None,
        arguments: Optional[KeywordArguments] = None,
        arguments_sets: Optional[ArgumentsSets] = None,
        run_name: Optional[str] = None,
        note: Optional[str] = None,
        development_mode: bool = False,
        job_template_path: str = 'bin/templates/slurm.sh',
        cluster: str = 'cedar',
        cpus: int = 6,
        memory: str = '16G',
        gpu: str = '1',
        time: str = '1-0',
        directory: str = 'scratch',
        signal: str = 'B:USR1@300',
) -> None:
    """
    Launches a Kubernetes Job that runs an MLFlow entry point

    :param experiment_name: The MLFlow experiment name
    :param entry_point: The name of the MLFlow entry point
    :param version: A commit hash, branch name or tag name, specifying the version of the code to run
    :param run_id: MLFlow run ID to continue
    :param arguments: Semicolon-separated list of key=value arguments for the entry point
    :param arguments_sets: Semicolon-separated list of key=[value1,value2] arguments sets for the entry point
    :param run_name: Run name.
    :param note: Note for the run.
    :param development_mode: Whether to launch the job in development mode
    :param job_template_path: Job template path
    :param cluster: Label of the Slurm host and account to use
    :param cpus:  Number of the CPUs for the job
    :param memory: Amount of memory for the job
    :param gpu: GPU specification for the job
    :param time: Maximum time allowed for the job to run
    :param directory: Directory where the command should be run
    :param signal: Process signal to send to the job before it is terminated
    """
    assert experiment_name or run_id
    assert entry_point or run_id
    assert arguments is None or 'run-id' not in arguments

    arguments = arguments if arguments else get_arguments(run_id) if run_id else KeywordArguments()
    arguments_sets = arguments_sets if arguments_sets else ArgumentsSets()

    assert bool(arguments_sets) and not bool(run_id) or not bool(arguments_sets)

    experiment_name = experiment_name if experiment_name else get_experiment_name(run_id)
    entry_point = entry_point if entry_point else get_entry_point(run_id)
    version = run_command('git', 'rev-parse', version if version else get_version(run_id) if run_id else 'HEAD')

    repository_url = get_repository_url()
    path = run_command('git', 'rev-parse', '--show-prefix').strip('/')
    branch = run_command('git', 'branch', '--show-current')

    host, account_id = CLUSTERS[cluster]

    with io.open(os.path.join(os.getcwd(), job_template_path), mode='r') as job_file:
        job_template = job_file.read()

    job_name = f'{entry_point}-{version}'

    argument_combinations = get_argument_combinations(arguments_sets) or [{}]

    with Connection(host, connect_kwargs={'passphrase': os.getenv('SSH_PASSPHRASE')}) as connection:
        for argument_combination in argument_combinations:
            if argument_combination:
                arguments_string = ', '.join((f'{key}={value}' for key, value in argument_combination.items()))
                print(f'Launching argument combination: {arguments_string}')

            if not run_id or bool(arguments_sets):
                run_id = create_run_id(
                    experiment_name=experiment_name,
                    user=os.environ['USER'],
                    entry_point=entry_point,
                    repository_url=repository_url,
                    version=version,
                    branch=branch,
                    path=path,
                    image=os.environ['TRAINING_IMAGE'],
                    run_name=run_name,
                    note=note,
                )

            arguments['run-id'] = run_id

            job_arguments = [
                f'"{argument}"' for argument in
                [
                    f'https://{os.environ["GITHUB_TOKEN"]}@{repository_url}#{path}',
                    '--experiment-name', experiment_name,
                    '--entry-point', entry_point,
                    '--version', version,
                    '--run-id', run_id,
                ] + [
                    argument
                    for key, value in (arguments | argument_combination).items()
                    for argument in ('-P', f'{key}={value}')
                ]
            ]

            job_definition = job_template.format(
                account_id=account_id,
                job_name=job_name,
                cpus=cpus,
                memory=memory,
                gpu=gpu,
                time=time,
                signal=signal,
                docker_username=os.environ['DOCKER_USERNAME'],
                docker_password=os.environ['DOCKER_PASSWORD'],
                mlflow_username=os.environ['MLFLOW_TRACKING_USERNAME'],
                mlflow_password=os.environ['MLFLOW_TRACKING_PASSWORD'],
                aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
                aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],
                proxy_url=os.environ['PROXY_URL'],
                slack_url=os.environ['SLACK_URL'],
                slack_user=os.getenv('SLACK_USER', ''),
                training_image=os.environ['TRAINING_IMAGE'],
                development_mode=development_mode,
                job_arguments=' '.join(job_arguments),
            )

            connection.run(f'(cd {directory} && /bin/bash -s)', in_stream=StringIO(job_definition))


if __name__ == '__main__':
    defopt.run(
        funcs=main,
        parsers={
            KeywordArguments: KeywordArguments.from_string,
            ArgumentsSets: ArgumentsSets.from_string,
        },
    )
